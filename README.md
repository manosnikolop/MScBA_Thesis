# MScBA Thesis - Gender bias with word embedding on the full Greek Wikipedia page
This thesis goal was to identify gender bias, using a model (with gensim's word2vec) that was trained on the full corpus of the Greek Wikipedia page.

The "Why":

Gender stereotypes are deeply rooted in our society and have been around almost since the birth of our structured civilization. Women grow up being treated differently and although the age of gender discrimination is almost at its end, gender bias has yet to be dismissed entirely.

The roots of gender bias can be traced in one of our most common daily tools: Language. Grammatical and syntactical rules, common terms, nouns and adjectives and many other aspects of language, seem to be built in such a way that a bias is almost certain in a conscious or (more often) a subconscious level. For example, when someone hears the Greek word “δικηγόρος” he will most likely picture a man. When he hears the word “προγραμματιστής”, he will do the same thing. And when he imagines these 2 professions, he will most likely imagine the female equivalent to be “νοικοκυρά” or ‘νοσοκόμα’, or things in general we have gotten used to link to women. Another good example would be to think the adjectives used to describe a man (“αρρενωπός”, “έξυπνος”, “δυνατός”,”μυώδης”,etc.) and a woman (“θηλυκή”,”γλυκιά”,”όμορφη”, etc.). We can see that the more masculine adjectives and the adjectives that designate some form of ability are used for men, while for women we keep the more adjectives that depict looks and character. 

The above can be a disadvantage for women, not only in terms of how we think about them, but in every day aspects of life as well. For example, when a recruiter is looking to hire for a position that is more traditionally filled by men, he may overlook a good candidate because of her gender. And to bring things closer to our topic, gender bias can be found in machine learning algorithms as well, mostly in the field of Natural Language Processing (NLP). 

NLP deals with the interaction between computers and humans using the natural language.  Most NLP techniques rely on machine learning to derive meaning from human languages, but machine learning must use text to learn from and if our language is biased, then so is our writing, hence we are producing algorithms that have the same bias as we do.
